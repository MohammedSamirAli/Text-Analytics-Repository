{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d3e339",
   "metadata": {},
   "source": [
    "# Lab Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f181c",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93054a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3b4ce",
   "metadata": {},
   "source": [
    "### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc05eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Bag-of-Words matrix: (568454, 120252)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_bow = count_vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Display the shape of the resulting matrix\n",
    "print(\"Shape of Bag-of-Words matrix:\", X_bow.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a37a12",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d014c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (568454, 120252)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Display the shape of the resulting matrix\n",
    "print(\"Shape of TF-IDF matrix:\", X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b60e1",
   "metadata": {},
   "source": [
    "### Successfully transformed the text data into numerical features using both Bag-of-Words and TF-IDF representations. The resulting matrices have the same shape, indicating that they contain the same number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ac191",
   "metadata": {},
   "source": [
    "### lexicon-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fef481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/hamody/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text LexiconSentiment\n",
      "0  I have bought several of the Vitality canned d...         positive\n",
      "1  Product arrived labeled as Jumbo Salted Peanut...         negative\n",
      "2  This is a confection that has been around a fe...         positive\n",
      "3  If you are looking for the secret ingredient i...          neutral\n",
      "4  Great taffy at a great price.  There was a wid...         positive\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download VADER lexicon if not already downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to get sentiment scores\n",
    "def get_sentiment(text):\n",
    "    scores = sid.polarity_scores(text)\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the function to each review text\n",
    "df['LexiconSentiment'] = df['Text'].apply(get_sentiment)\n",
    "\n",
    "# Display the first few rows of the DataFrame with sentiment labels\n",
    "print(df[['Text', 'LexiconSentiment']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb2241",
   "metadata": {},
   "source": [
    "### machine-learning based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70714c3e",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe96d76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6499722933213711\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.09      0.16     10326\n",
      "           2       0.20      0.00      0.00      5855\n",
      "           3       0.41      0.00      0.00      8485\n",
      "           4       0.65      0.01      0.02     16123\n",
      "           5       0.65      1.00      0.79     72902\n",
      "\n",
      "    accuracy                           0.65    113691\n",
      "   macro avg       0.55      0.22      0.19    113691\n",
      "weighted avg       0.62      0.65      0.52    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the sentiment labels for the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900693aa",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944f4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7591805859742635\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.72      0.70     10326\n",
      "           2       0.54      0.27      0.36      5855\n",
      "           3       0.52      0.36      0.43      8485\n",
      "           4       0.55      0.29      0.38     16123\n",
      "           5       0.81      0.95      0.88     72902\n",
      "\n",
      "    accuracy                           0.76    113691\n",
      "   macro avg       0.62      0.52      0.55    113691\n",
      "weighted avg       0.73      0.76      0.73    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the sentiment labels for the test set\n",
    "y_pred_lr = lr_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "\n",
    "# Define the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine the features and target variable for training data\n",
    "train_data = pd.concat([pd.DataFrame(X_train.toarray()), y_train.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Separate minority and majority classes\n",
    "minority_class = train_data[train_data['Score'] != 5]\n",
    "majority_class = train_data[train_data['Score'] == 5]\n",
    "\n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "upsampled_data = pd.concat([majority_class, minority_upsampled])\n",
    "\n",
    "# Split features and target variable\n",
    "X_train_balanced = upsampled_data.drop('Score', axis=1)\n",
    "y_train_balanced = upsampled_data['Score']\n",
    "\n",
    "# Initialize and train the Logistic Regression classifier with balanced data\n",
    "lr_classifier_balanced = LogisticRegression(max_iter=1000)\n",
    "lr_classifier_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict the sentiment labels for the test set\n",
    "y_pred_lr_balanced = lr_classifier_balanced.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier with balanced data\n",
    "accuracy_lr_balanced = accuracy_score(y_test, y_pred_lr_balanced)\n",
    "print(\"Logistic Regression Accuracy with Resampling:\", accuracy_lr_balanced)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr_balanced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ff9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
