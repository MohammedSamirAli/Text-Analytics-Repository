{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acddb5c1",
   "metadata": {},
   "source": [
    "# Lab Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6c706",
   "metadata": {},
   "source": [
    "## Mohammed Samir Ali (SW01080809)\n",
    "## Muhammad Farish Naufal Bin Norzali (SW01081139)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd9e1d",
   "metadata": {},
   "source": [
    "### Import Libraries & Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a30de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hamody/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hamody/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/hamody/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaebdf3",
   "metadata": {},
   "source": [
    "### Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71905f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data (use only the ‘text’ column)\n",
    "df = pd.read_csv('news_dataset.csv', usecols=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464ca0c",
   "metadata": {},
   "source": [
    "### Perform text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4338daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "# Initialize stopwords, lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words and convert to lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Filter out non-alphanumeric tokens and remove stopwords\n",
    "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    # Lemmatize each tokenn\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to each document in the dataset\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3dfe27",
   "metadata": {},
   "source": [
    "### LDA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc521835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gensim Dictionary object from the preprocessed documents\n",
    "dictionary = corpora.Dictionary(df['processed_text'])\n",
    "# Convert each preprocessed document into a bag-of-words representation using the dictionary\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df['processed_text']]\n",
    "\n",
    "# Train an LDA model on the corpus with 4 topics using Gensim's LdaModel class\n",
    "lda_model = LdaModel(corpus, num_topics=4, id2word=dictionary, passes=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8c5b8",
   "metadata": {},
   "source": [
    "### Coherence Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e961d8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Coherence Score (C_V): 0.6691\n"
     ]
    }
   ],
   "source": [
    "# Calculate the coherence score for the LDA model\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['processed_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "# Display the Topic Coherence Score\n",
    "print(f'Topic Coherence Score (C_V): {coherence_lda:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b48ade",
   "metadata": {},
   "source": [
    "### Results Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f89449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Terms for Each Topic:\n",
      "Topic 0:\n",
      "- \"1\" (weight: 0.032)\n",
      "- \"max\" (weight: 0.026)\n",
      "- \"0\" (weight: 0.026)\n",
      "- \"q\" (weight: 0.023)\n",
      "- \"2\" (weight: 0.021)\n",
      "- \"g\" (weight: 0.017)\n",
      "- \"r\" (weight: 0.016)\n",
      "- \"7\" (weight: 0.016)\n",
      "- \"3\" (weight: 0.014)\n",
      "- \"p\" (weight: 0.013)\n",
      "\n",
      "Topic 1:\n",
      "- \"x\" (weight: 0.017)\n",
      "- \"key\" (weight: 0.011)\n",
      "- \"file\" (weight: 0.008)\n",
      "- \"use\" (weight: 0.006)\n",
      "- \"system\" (weight: 0.006)\n",
      "- \"program\" (weight: 0.005)\n",
      "- \"encryption\" (weight: 0.005)\n",
      "- \"chip\" (weight: 0.005)\n",
      "- \"information\" (weight: 0.005)\n",
      "- \"available\" (weight: 0.004)\n",
      "\n",
      "Topic 2:\n",
      "- \"db\" (weight: 0.010)\n",
      "- \"one\" (weight: 0.007)\n",
      "- \"would\" (weight: 0.006)\n",
      "- \"get\" (weight: 0.005)\n",
      "- \"like\" (weight: 0.005)\n",
      "- \"drive\" (weight: 0.005)\n",
      "- \"window\" (weight: 0.005)\n",
      "- \"use\" (weight: 0.005)\n",
      "- \"problem\" (weight: 0.005)\n",
      "- \"know\" (weight: 0.004)\n",
      "\n",
      "Topic 3:\n",
      "- \"would\" (weight: 0.008)\n",
      "- \"one\" (weight: 0.007)\n",
      "- \"people\" (weight: 0.007)\n",
      "- \"think\" (weight: 0.005)\n",
      "- \"know\" (weight: 0.004)\n",
      "- \"time\" (weight: 0.004)\n",
      "- \"say\" (weight: 0.004)\n",
      "- \"like\" (weight: 0.004)\n",
      "- \"right\" (weight: 0.004)\n",
      "- \"year\" (weight: 0.004)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top terms for each topic\n",
    "print(\"\\nTop Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94589d11",
   "metadata": {},
   "source": [
    "### Interpretation of the coherence score\n",
    "Interpretation of the Coherence Score:\n",
    "The coherence score of 0.6691 indicates the degree of semantic similarity between the top words in each topic generated by the LDA model. A higher coherence score generally suggests that the topics are more interpretable and meaningful to humans. For practical applications, a higher coherence score is desirable as it implies that the topics are more coherent and easier to understand, leading to more useful insights from the data. In this case, the score provides a quantitative measure of the quality of the topics derived from the news articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d3484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
